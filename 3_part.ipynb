{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal, Images, and Video Project: Substituting Closed Eyes with Open Eyes in Images using DCGAN\n",
    "\n",
    "In this project, we aim to substitute closed eyes in images with open eyes and open eyes in images with closed eyes using a Deep Convolutional Generative Adversarial Network (DCGAN) architecture. The input to the project consists of 5000 sample images of faces manually divided into opened and closed eyes taken from the Flickr-Faces-HQ Dataset (FFHQ) (https://github.com/NVlabs/ffhq-dataset).\n",
    "\n",
    "A DCGAN is a type of generative model that is designed to generate new data that is similar to a training dataset. In this project, the DCGAN will be trained on the 5000 sample images of faces with either open or closed eyes to generate new images of faces with substituted eyes. The DCGAN architecture consists of two main components: a generator and a discriminator. The generator is trained to generate new images that are similar to the training data, while the discriminator is trained to determine whether an image is real or generated.\n",
    "\n",
    "The DCGAN architecture is defined using the Keras library and consists of Convolutional Neural Networks (CNNs). The generator and discriminator models are first defined separately and then compiled into a combined model. The combined model is trained using the `fit()` function from Keras, with the training data, batch size, number of epochs, and other parameters specified.\n",
    "\n",
    "The expected output of the project is a set of generated images of faces with substituted eyes. The quality of the generated images will be evaluated based on factors such as similarity to the training data and the sharpness of the generated images. The results will be displayed and saved as image files.\n",
    "\n",
    "This project provides a unique opportunity to explore the use of DCGANs in image generation tasks and to gain insights into the capabilities and limitations of this type of model. With the expected results, we aim to demonstrate the potential of DCGANs in generating high-quality images of faces with substituted eyes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load, pre-process and split into training and validation data\n",
    "The method `load_data_gen` loads and prepares a dataset for training and validation of a machine learning model. The method takes three inputs, the paths to the two directories containing the data of interest (open eyes and closed eyes), and the batch size. Firstly, the filenames and labels of the data are collected and stored in separate lists. The labels represent the binary classes of open eyes and closed eyes. The data is then shuffled to ensure that the model is not trained on ordered data. The shuffled data is then split into training and validation sets.\n",
    "\n",
    "The method then defines a generator function, which takes in the filenames and labels, and yields the image data and corresponding label for each iteration. The generator is then used to create two datasets, one for the training set and one for the validation set. These datasets are created using the tf.data.Dataset.from_generator method, which converts the generator into a TensorFlow dataset. The datasets are then batched to the specified batch size. Finally, the prepared training and validation datasets are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from typing import Tuple\n",
    "import os\n",
    "\n",
    "def load_data_gen(path_open_eyes: str, path_closed_eyes: str, batch_size: int) -> Tuple:\n",
    "\tfilenames = []\n",
    "\tlabels = []\n",
    "\n",
    "\tfor filename in os.listdir(path_open_eyes):\n",
    "\t\tif filename.endswith(\".ini\"):\n",
    "\t\t\tcontinue\n",
    "\t\tfilenames.append(os.path.join(path_open_eyes, filename))\n",
    "\t\tlabels.append([1.0, 0.0])\n",
    "\n",
    "\tfor filename in os.listdir(path_closed_eyes):\n",
    "\t\tif filename.endswith(\".ini\"):\n",
    "\t\t\tcontinue\n",
    "\t\tfilenames.append(os.path.join(path_closed_eyes, filename))\n",
    "\t\tlabels.append([0.0, 1.0])\n",
    "\n",
    "\t# shuffle the data\n",
    "\tidx = np.arange(len(filenames))\n",
    "\tnp.random.shuffle(idx)\n",
    "\tfilenames = [filenames[i] for i in idx]\n",
    "\tlabels = [labels[i] for i in idx]\n",
    "\n",
    "\t# split the data into training and validation sets\n",
    "\tsplit = int(0.8 * len(filenames))\n",
    "\tfilenames_train = filenames[:split]\n",
    "\tlabels_train = labels[:split]\n",
    "\tfilenames_val = filenames[split:]\n",
    "\tlabels_val = labels[split:]\n",
    "\n",
    "\tdef generator(filenames, labels):\n",
    "\t\tfor filename, label in zip(filenames, labels):\n",
    "\t\t\timage = Image.open(filename)\n",
    "\t\t\timage = image.resize((128, 128))\n",
    "\t\t\timage = np.array(image, dtype=np.float32)\n",
    "\t\t\timage = (image - 127.5) / 127.5\n",
    "\t\t\tyield image, label\n",
    "\n",
    "\t# create the training and validation generators\n",
    "\ttrain_gen = generator(filenames_train, labels_train)\n",
    "\tval_gen = generator(filenames_val, labels_val)\n",
    "\n",
    "\t# create the training and validation datasets\n",
    "\ttrain_ds = tf.data.Dataset.from_generator(lambda: train_gen, (tf.float32, tf.float32), ((128, 128, 3), (2,)))\n",
    "\ttrain_ds = train_ds.batch(batch_size)\n",
    "\tval_ds = tf.data.Dataset.from_generator(lambda: val_gen, (tf.float32, tf.float32), ((128, 128, 3), (2,)))\n",
    "\tval_ds = val_ds.batch(batch_size)\n",
    "\n",
    "\treturn train_ds, val_ds\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_ds, val_ds = load_data_gen(\"dataset_1024/eyes_open/\", \"dataset_1024/eyes_closed/\", batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Build the generator and discriminator of the GAN\n",
    "The code defines two functions, `build_generator` and `build_discriminator`, which return instances of the `Sequential` model from Tensorflow's Keras library. The build_generator function takes in a `latent_dim` parameter and returns a `Sequential` model that generates an image. The `build_discriminator` function takes in an `img_shape` parameter, which is the shape of the input image, and returns a `Sequential` model that discriminates between real and generated images.\n",
    "\n",
    "The `build_generator` function starts by creating a `Sequential` model and adding a `Dense` layer with 128 * 8 * 8 units, which is reshaped into an 8 x 8 x 128 tensor. This tensor goes through a series of `Conv2DTranspose` layers, each with a `BatchNormalization` layer followed by a `ReLU` activation layer, to increase the spatial dimensions of the tensor. The final layer is a `Conv2DTranspose` layer with 3 filters and a `tanh` activation function.\n",
    "\n",
    "The `build_discriminator` function starts by creating a `Sequential` model and adding a series of `Conv2D` layers with `LeakyReLU` activation functions, each followed by a `BatchNormalization` layer. The spatial dimensions of the input tensor are reduced with each `Conv2D` layer, with the final layer having a single output unit and a `tanh` activation function. This output is used to determine whether the input image is real or generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, LeakyReLU, Conv2DTranspose, ReLU, Activation, Dense, Flatten, Reshape, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from typing import Tuple\n",
    "\n",
    "def build_generator(latent_dim:int) -> Model:\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128 * 128 * 3, activation=\"relu\", input_dim=latent_dim))\n",
    "\tmodel.add(Reshape((128, 128, 3)))\n",
    "\tmodel.add(Conv2DTranspose(128, kernel_size=4, strides=1, padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(ReLU())\n",
    "\tmodel.add(Conv2DTranspose(64, kernel_size=4, strides=1, padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(ReLU())\n",
    "\tmodel.add(Conv2DTranspose(32, kernel_size=4, strides=1, padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(ReLU())\n",
    "\tmodel.add(Conv2DTranspose(3, kernel_size=4, strides=1, padding='same'))\n",
    "\tmodel.add(Activation('tanh'))\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def build_discriminator(img_shape:Tuple) -> Model:\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\t# Use the tanh activation \n",
    "\tmodel.add(Dense(1, activation='tanh'))\n",
    "\treturn model\n",
    "\n",
    "latent_dim = 100\n",
    "img_shape = train_ds.element_spec[0].shape[1:]\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(img_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the models\n",
    "The compile_models function takes the `generator` and `discriminator` as inputs and creates a combined model by connecting the two.\n",
    "The `discriminator` is set to untrainable with `discriminator.trainable = False`, meaning its weights will not be updated during the training of the combined model.\n",
    "\n",
    "The combined model takes in a `latent_dim`-shaped tensor as input and outputs the validity of the generated image as determined by the `discriminator`.\n",
    "The combined model is then compiled with a binary cross-entropy loss function and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "def compile_models(generator:Model, discriminator:Model) -> Model:\n",
    "\t# set to False so that the weights of the discriminator are not updated during the training of the combined model\n",
    "\tdiscriminator.trainable = False\n",
    "\n",
    "\tz = Input(shape=(latent_dim,))\n",
    "\timg = generator(z)\n",
    "\n",
    "\tvalid = discriminator(img)\n",
    "\n",
    "\tcombined = Model(z, valid)\n",
    "\tcombined.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\treturn combined\n",
    "\n",
    "combined = compile_models(generator, discriminator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "Train the generator and discriminator models in a GAN framework, where the generator tries to generate images that the discriminator cannot differentiate from real images, and the discriminator tries to correctly identify whether an image is real or generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in batches: 0it [00:05, ?it/s]\n",
      "Epochs:   0%|          | 0/100 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \t\t\t\u001b[39m# print the losses\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \t\t\t\u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m [D loss: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m, acc: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m] [G loss: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (epoch, d_loss[\u001b[39m0\u001b[39m], \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m d_loss[\u001b[39m1\u001b[39m], g_loss))\n\u001b[1;32m---> 24\u001b[0m train(combined, train_ds, latent_dim, \u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(combined, dataset, latent_dim, epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, (batch_size, latent_dim))\n\u001b[0;32m     12\u001b[0m gen_imgs \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39mpredict(z)\n\u001b[1;32m---> 13\u001b[0m d_loss_real \u001b[39m=\u001b[39m discriminator\u001b[39m.\u001b[39;49mtrain_on_batch(imgs, valid)\n\u001b[0;32m     14\u001b[0m d_loss_fake \u001b[39m=\u001b[39m discriminator\u001b[39m.\u001b[39mtrain_on_batch(gen_imgs, fake)\n\u001b[0;32m     15\u001b[0m d_loss \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39madd(d_loss_real, d_loss_fake)\n",
      "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py:2369\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_on_batch\u001b[39m(\n\u001b[0;32m   2322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   2323\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2328\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   2329\u001b[0m ):\n\u001b[0;32m   2330\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Runs a single gradient update on a single batch of data.\u001b[39;00m\n\u001b[0;32m   2331\u001b[0m \n\u001b[0;32m   2332\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2367\u001b[0m \u001b[39m      RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.\u001b[39;00m\n\u001b[0;32m   2368\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2369\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assert_compile_was_called()\n\u001b[0;32m   2370\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m\"\u001b[39m\u001b[39mtrain_on_batch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2371\u001b[0m     _disallow_inside_tf_function(\u001b[39m\"\u001b[39m\u001b[39mtrain_on_batch\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py:3618\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_compile_was_called\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   3613\u001b[0m     \u001b[39m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[0;32m   3614\u001b[0m     \u001b[39m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[0;32m   3615\u001b[0m     \u001b[39m# model is compiled\u001b[39;00m\n\u001b[0;32m   3616\u001b[0m     \u001b[39m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[0;32m   3617\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_compiled:\n\u001b[1;32m-> 3618\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   3619\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must compile your model before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3620\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtraining/testing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3621\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3622\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(combined:Model, dataset:tf.data.Dataset, latent_dim:int, epochs:int):\n",
    "\tfor epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "\t\tfor x_batch in tqdm(dataset, desc=\"Training in batches\"):\n",
    "\t\t\tvalid = np.ones((batch_size, 1))\n",
    "\t\t\tfake = np.zeros((batch_size, 1))\n",
    "\n",
    "\t\t\t# train the discriminator to classify real and fake images\n",
    "\t\t\timgs = x_batch\n",
    "\t\t\tz = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\t\t\tgen_imgs = generator.predict(z)\n",
    "\t\t\td_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "\t\t\td_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\t\t\td_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\t\t\t# train the generator to produce images that can fool the discriminator\n",
    "\t\t\tz = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\t\t\tg_loss = combined.train_on_batch(z, valid)\n",
    "\n",
    "\t\t\t# print the losses\n",
    "\t\t\tprint(\"%d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "train(combined, train_ds, latent_dim, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new images\n",
    "After training, use the generator model to generate new images with closed eyes open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/dense/Relu' defined at (most recent call last):\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\maxst\\AppData\\Local\\Temp\\ipykernel_31172\\2008095391.py\", line 7, in <module>\n      generate_images(generator, data, 10)\n    File \"C:\\Users\\maxst\\AppData\\Local\\Temp\\ipykernel_31172\\2008095391.py\", line 2, in generate_images\n      predictions = generator.predict(data)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/dense/Relu'\nIn[0] and In[1] has different ndims: [32,128,128,3] vs. [100,8192]\n\t [[{{node sequential/dense/Relu}}]] [Op:__inference_predict_function_4187]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \t\tplt\u001b[39m.\u001b[39mimshow(predictions[i, :, :, \u001b[39m0\u001b[39m], cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \t\tplt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m----> 7\u001b[0m generate_images(generator, data, \u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m, in \u001b[0;36mgenerate_images\u001b[1;34m(generator, data, n_images)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_images\u001b[39m(generator: Model, data: np\u001b[39m.\u001b[39mndarray, n_images: \u001b[39mint\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m \tpredictions \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39;49mpredict(data)\n\u001b[0;32m      3\u001b[0m \t\u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_images):\n\u001b[0;32m      4\u001b[0m \t\tplt\u001b[39m.\u001b[39mimshow(predictions[i, :, :, \u001b[39m0\u001b[39m], cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/dense/Relu' defined at (most recent call last):\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\maxst\\AppData\\Local\\Temp\\ipykernel_31172\\2008095391.py\", line 7, in <module>\n      generate_images(generator, data, 10)\n    File \"C:\\Users\\maxst\\AppData\\Local\\Temp\\ipykernel_31172\\2008095391.py\", line 2, in generate_images\n      predictions = generator.predict(data)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\maxst\\miniconda3\\envs\\siv\\lib\\site-packages\\keras\\backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/dense/Relu'\nIn[0] and In[1] has different ndims: [32,128,128,3] vs. [100,8192]\n\t [[{{node sequential/dense/Relu}}]] [Op:__inference_predict_function_4187]"
     ]
    }
   ],
   "source": [
    "def generate_images(generator: Model, data: np.ndarray, n_images: int):\n",
    "\tpredictions = generator.predict(data)\n",
    "\tfor i in range(n_images):\n",
    "\t\tplt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "\t\tplt.show()\n",
    "\n",
    "generate_images(generator, data, 10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display and save the results\n",
    "Finally, display and save the results by plotting the generated images and the original images side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 4 dimension(s) and the array at index 1 has 0 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     plt\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39mconcatenate([data, generated_images], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m      4\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m----> 6\u001b[0m display_results(data, generated_images)\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mdisplay_results\u001b[1;34m(data, generated_images)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdisplay_results\u001b[39m(data, generated_images):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# plot the results\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     plt\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39;49mconcatenate([data, generated_images], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m      4\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 4 dimension(s) and the array at index 1 has 0 dimension(s)"
     ]
    }
   ],
   "source": [
    "def display_results(data, generated_images):\n",
    "    # plot the results\n",
    "    plt.imshow(np.concatenate([data, generated_images], axis=1))\n",
    "    plt.show()\n",
    "\n",
    "display_results(data, generated_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf758b4e31a264a7d350682862ef5f8d75991173714a052f5e5930abba6bdf81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
